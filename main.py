import streamlit as st
from PIL import Image
import cv2
import io
import numpy as np
import torch
import albumentations as albu

# -----------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# -----------------------------
CLASSES = ["—Ñ–æ–Ω", "–ª–∏–Ω–∏—è"]
INFER_WIDTH = 256
INFER_HEIGHT = 256
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]
MODEL_PATH = "models/best_model_new.pt"   # <-- –ø—É—Ç—å –∫ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def compute_metrics(pred_mask: np.ndarray, true_mask: np.ndarray, class_index: int = 1):
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –∫–ª–∞—Å—Å—É).
    pred_mask, true_mask: 2D numpy arrays (H, W), –∑–Ω–∞—á–µ–Ω–∏—è {0,1,...}
    """
    pred = (pred_mask == class_index).astype(np.uint8)
    true = (true_mask == class_index).astype(np.uint8)

    intersection = np.logical_and(pred, true).sum()
    union = np.logical_or(pred, true).sum()

    dice = (2 * intersection) / (pred.sum() + true.sum() + 1e-7)
    iou = intersection / (union + 1e-7)
    acc = (pred == true).mean()

    return {
        "IoU": round(float(iou), 4),
        "Dice": round(float(dice), 4),
        "Accuracy": round(float(acc), 4),
    }

def to_bytes(img: np.ndarray) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç numpy-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PNG-–±–∞–π—Ç—ã –¥–ª—è st.download_button."""
    pil_img = Image.fromarray(img)
    buf = io.BytesIO()
    pil_img.save(buf, format="PNG")
    return buf.getvalue()

# -----------------------------
# –ö—ç—à: –º–æ–¥–µ–ª—å –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
# -----------------------------
@st.cache_resource
def load_model(path: str):
    model = torch.jit.load(path, map_location=DEVICE)
    model.eval()
    return model

@st.cache_data
def get_validation_augmentation():
    return albu.Compose([
        albu.LongestMaxSize(max_size=INFER_HEIGHT, always_apply=True),
        albu.PadIfNeeded(min_height=INFER_HEIGHT, min_width=INFER_WIDTH, always_apply=True),
        albu.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ])

# -----------------------------
# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
# -----------------------------
def infer_image_with_model(image: np.ndarray, model: torch.nn.Module):
    original_height, original_width, _ = image.shape
    augmentation = get_validation_augmentation()
    augmented = augmentation(image=image)
    image_transformed = augmented["image"]

    x_tensor = (
        torch.from_numpy(image_transformed)
        .to(DEVICE)
        .unsqueeze(0)
        .permute(0, 3, 1, 2)
        .float()
    )

    with torch.no_grad():
        pr = model(x_tensor)

    pr = pr.squeeze().cpu().numpy()          # (C, H, W)
    label_mask = np.argmax(pr, axis=0)       # (H, W)

    # –£–±–∏—Ä–∞–µ–º –ø–∞–¥–¥–∏–Ω–≥–∏ –æ—Ç –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
    if original_height > original_width:
        delta = int(((original_height - original_width) / 2) / original_height * INFER_HEIGHT)
        mask_cropped = label_mask[:, delta: INFER_WIDTH - delta]
    elif original_height < original_width:
        delta = int(((original_width - original_height) / 2) / original_width * INFER_WIDTH)
        mask_cropped = label_mask[delta: INFER_HEIGHT - delta, :]
    else:
        mask_cropped = label_mask

    mask_real = cv2.resize(mask_cropped, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
    return mask_real

# -----------------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ UI/–æ–±—Ä–∞–±–æ—Ç–∫–∏
# -----------------------------
def overlay_mask(img_rgb: np.ndarray, mask: np.ndarray, alpha: float = 0.45):
    """–ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –æ–≤–µ—Ä–ª–µ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –º–∞—Å–∫–∏."""
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    # –ü–æ–¥—Å–≤–µ—Ç–∏–º –∫–ª–∞—Å—Å "–ª–∏–Ω–∏—è" (index=1) —Ü–≤–µ—Ç–æ–º
    color = (0, 255, 255)  # –∂–µ–ª—Ç—ã–π –≤ BGR
    overlay = img_bgr.copy()
    overlay[mask == 1] = (overlay[mask == 1] * (1 - alpha) + np.array(color) * alpha).astype(np.uint8)
    out = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)
    return out

def adjust_hsv(image: np.ndarray, mask: np.ndarray, h_adjust: int, s_adjust: int, v_adjust: int, index: int):
    """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ HSV –≤ –æ–±–ª–∞—Å—Ç–∏ mask == index."""
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32)
    h, s, v = cv2.split(hsv)

    m = (mask == index)
    h[m] = np.clip(h[m] + h_adjust, 0, 179)
    s[m] = np.clip(s[m] + s_adjust, 0, 255)
    v[m] = np.clip(v[m] + v_adjust, 0, 255)

    out = cv2.merge([h, s, v]).astype(np.uint8)
    return cv2.cvtColor(out, cv2.COLOR_HSV2RGB)

def to_pil(img: np.ndarray) -> Image.Image:
    return Image.fromarray(img)

# -----------------------------
# UI
# -----------------------------
def main():
    st.set_page_config(page_title="Line Segmentation", page_icon="üß†", layout="wide")

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã—Å–æ—Ç—É –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—ã—Å–æ—Ç–æ–π –æ–∫–Ω–∞, —Ç—è–Ω–µ–º –Ω–∞ –≤—Å—é —à–∏—Ä–∏–Ω—É
    st.markdown("""
        <style>
        .stImage img {
            width: 100% !important;      /* —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ–º –ø–æ —à–∏—Ä–∏–Ω–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ */
            height: auto !important;      /* —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ */
            max-height: 85vh !important;  /* –Ω–µ –≤—ã—à–µ 85% –≤—ã—Å–æ—Ç—ã —ç–∫—Ä–∞–Ω–∞ */
            object-fit: contain !important;
        }
        </style>
    """, unsafe_allow_html=True)

    st.title("üß† Line Segmentation")
    st.caption("DeepLabV3+")

    with st.sidebar:
        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
        st.markdown("**–ú–æ–¥–µ–ª—å:**")
        st.code(MODEL_PATH, language="text")
        alpha = st.slider("–ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –º–∞—Å–∫–∏", 0.0, 1.0, 0.45, 0.05)

        st.markdown("---")
        st.subheader("HSV-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è")
        h_adjust = st.slider("–û—Ç—Ç–µ–Ω–æ–∫ (H)", -179, 179, 0)
        s_adjust = st.slider("–ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å (S)", -255, 255, 0)
        v_adjust = st.slider("–Ø—Ä–∫–æ—Å—Ç—å (V)", -255, 255, 0)
        region = st.selectbox("–û–±–ª–∞—Å—Ç—å", CLASSES)
        index = CLASSES.index(region)

        st.markdown("---")
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JPG/PNG. –ú–∞—Å–∫–∞ –ø–æ–¥—Å–≤–µ—á–∏–≤–∞–µ—Ç –∫–ª–∞—Å—Å ¬´–ª–∏–Ω–∏—è¬ª.", icon="‚ÑπÔ∏è")

    st.markdown("---")
    st.subheader("–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ")
    scale_percent = st.slider("–ú–∞—Å—à—Ç–∞–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (%)", 10, 100, 50, 5)

    def resize_img(img: np.ndarray, scale: int) -> np.ndarray:
        """–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º."""
        h, w = img.shape[:2]
        new_w = int(w * scale / 100)
        new_h = int(h * scale / 100)
        return cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–∫—ç—à–∏—Ä.)
    model = load_model(MODEL_PATH)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"])
    if uploaded is None:
        st.stop()

    image = np.array(Image.open(uploaded).convert("RGB"))

    # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
    mask = infer_image_with_model(image, model)

    # --- –í–ö–õ–ê–î–ö–ò –ò –û–¢–†–ò–°–û–í–ö–ê ---
    tab1, tab2, tab3 = st.tabs(["üñºÔ∏è –û—Ä–∏–≥–∏–Ω–∞–ª", "üéØ –ú–∞—Å–∫–∞", "üéõÔ∏è –†–µ–∑—É–ª—å—Ç–∞—Ç (HSV)"])

    # --- TAB 1: –û—Ä–∏–≥–∏–Ω–∞–ª ---
    with tab1:
        img_small = resize_img(image, scale_percent)
        st.image(img_small, caption="–û—Ä–∏–≥–∏–Ω–∞–ª", use_container_width=True)
        st.download_button(
            "–°–∫–∞—á–∞—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            data=to_bytes(img_small),
            file_name="original_small.png",
            mime="image/png"
        )

    # --- TAB 2: –ú–∞—Å–∫–∞ ---
    with tab2:
        col1, col2 = st.columns([2, 1])  # —Å–ª–µ–≤–∞ –ø–æ—à–∏—Ä–µ
        overlay = overlay_mask(image, mask, alpha=alpha)
        mask_vis = (mask == 1).astype(np.uint8) * 255

        with col1:
            st.image(overlay, caption="–û–≤–µ—Ä–ª–µ–π –º–∞—Å–∫–∏ (–∫–ª–∞—Å—Å ¬´–ª–∏–Ω–∏—è¬ª)", use_container_width=True)

        with col2:
            st.image(mask_vis, caption="–ú–∞—Å–∫–∞ (–ª–∏–Ω–∏—è)", use_container_width=True)

        st.download_button(
            "–°–∫–∞—á–∞—Ç—å –º–∞—Å–∫—É (–ª–∏–Ω–∏—è)",
            data=to_bytes(np.stack([mask_vis] * 3, axis=-1)),
            file_name="mask_line.png",
            mime="image/png"
        )
    # --- TAB 3: –†–µ–∑—É–ª—å—Ç–∞—Ç ---
    with tab3:
        adjusted = adjust_hsv(image, mask, h_adjust, s_adjust, v_adjust, index)
        adjusted_small = resize_img(adjusted, scale_percent)
        st.image(adjusted_small, caption=f"HSV-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è ‚Äî {CLASSES[index]}", use_container_width=True)

        st.download_button(
            "üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
            data=to_bytes(adjusted_small),
            file_name="adjusted_small.png",
            mime="image/png"
        )

if __name__ == "__main__":
    main()
>>>>>>> master
